# [Классификация комментариев](https://github.com/PavelNedviga/Portfolio#%D0%BF%D0%BE%D1%80%D1%82%D1%84%D0%BE%D0%BB%D0%B8%D0%BE) 
Представлен набор данных: комментариев и их бинарная классификация по степени токсичности. Нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Необходимо подготовить модель, которая отклассифицирует комментарии на позитивные и негативные. В наличии размеченный набор данных с классом "токсичности" правок.

Мы стремимся построить модель со значением метрики качества F1 не меньше 0.75.

## Используемый стек:    
CatBoost,     
LightGBM,     
NLTK,     
Pandas,      
Re,      
Torch,      
Transformers,      
Hyperopt,      
Numpy,      
SkLearn,      
машинное обучение

## Результат и выводы
Что выполнили, сделали, рассчитали:
1. Был открыт и изучен датасет. 
2. Мы рассмотрели различного рода преобразования текста в численные признаки:
    - Создание n-грамм
    - TF-IDF - частота употребления слова в совокупности с их важностью. 
    - Создание признаков (эмбеддингов) на базе BERT. 
3. Обучено два вида моделей на базе двух наборов признаков:
    - LightGBM
    - LogisticRegression
4. Получены результаты классификации. Не все из них удовлетворяют заданным параметрам точности. 

Нашей задачей было подготовить и найти модель с устраивающим нас показателем точности.
Подбеду тут одержала модель LightGBM на признаках TF-IDF с показателем `f1 = 0.771`. Следующей по качеству оказалась линейная регрессия с `f1 = 0.747`   